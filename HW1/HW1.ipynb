{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a121ed71-a872-4464-a8de-690eb44df7a8",
   "metadata": {},
   "source": [
    "## Homework #1: Prove the Gradients of the Sigmoid and Tanh Functions\n",
    "\n",
    "In this exercise, you are tasked with deriving the gradients of two common activation functions in deep learning: the sigmoid function and the tanh function. Prove each gradient and simplify your answers as much as possible.\n",
    "\n",
    "### 1. Sigmoid Function Gradient\n",
    "\n",
    "The sigmoid function is defined as:\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "#### Task\n",
    "1. Differentiate $\\sigma(x)$ with respect to $x$.\n",
    "2. Show that the derivative of $\\sigma(x)$ can be expressed in terms of $\\sigma(x)$ itself:\n",
    "   \n",
    "   $$\n",
    "   \\frac{d\\sigma(x)}{dx} = \\sigma(x)(1 - \\sigma(x))\n",
    "   $$\n",
    "\n",
    "**Hint:** To simplify your work, start by applying the chain rule to the expression $\\sigma(x) = \\left(1 + e^{-x}\\right)^{-1}$.\n",
    "\n",
    "### 2. Tanh Function Gradient\n",
    "\n",
    "The hyperbolic tangent function is defined as:\n",
    "\n",
    "$$\n",
    "\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}\n",
    "$$\n",
    "\n",
    "#### Task\n",
    "1. Differentiate $\\tanh(x)$ with respect to $x$.\n",
    "2. Show that the derivative of $\\tanh(x)$ can be expressed as:\n",
    "\n",
    "   $$\n",
    "   \\frac{d\\tanh(x)}{dx} = 1 - \\tanh(x)^2\n",
    "   $$\n",
    "\n",
    "**Hint:** You may want to express $\\tanh(x)$ in terms of $\\sigma(x)$, noting that $\\tanh(x) = 2\\sigma(2x) - 1$, as an alternative approach.\n",
    "\n",
    "### Submission\n",
    "\n",
    "1. Write out the derivations step-by-step.\n",
    "2. Simplify each result as much as possible.\n",
    "3. Confirm that your results mat4. Complete the derivations in a Jupyter notebook. Use markdown cells continaing Latex code.\n",
    "5. Submit your notebook by uploading it to either Google Colab or GitHub.\n",
    "6. Share the link to your notebook with idan.tobis@gmail.com.ch the expected gradient forms given above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3caa013",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0dcc2",
   "metadata": {},
   "source": [
    "### Qustion 1:\n",
    "\n",
    "---\n",
    "#### Formula 1:\n",
    "$$ \\sigma(x) = (1 + e^{-x})^{-1} $$\n",
    "---\n",
    "\n",
    "$$ u = 1 + e^{-x} , \\sigma(x) = u^{-1} $$\n",
    "$$ \\frac{d\\sigma}{dx} = \\frac{d\\sigma}{du} \\cdot \\frac{du}{dx} $$\n",
    "$$ \\frac{d\\sigma}{du} = \\frac{d}{du}(u^{-1}) = -1 \\cdot u^{-2} = -(1 + e^{-x})^{-2} $$\n",
    "$$ \\frac{du}{dx} = \\frac{d}{dx}(1 + e^{-x}) = 0 + e^{-x} \\cdot \\frac{d}{dx}(-x) = e^{-x} \\cdot (-1) = -e^{-x}$$\n",
    "---\n",
    "#### Formula 2:\n",
    "$$ \\frac{d\\sigma}{dx}= \\left( -(1 + e^{-x})^{-2} \\right) \\cdot \\left( -e^{-x} \\right) = \\left( \\frac{1}{1 + e^{-x}} \\right) \\cdot \\left( \\frac{e^{-x}}{1 + e^{-x}} \\right)\n",
    "$$\n",
    "---\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "$$1 - \\sigma(x) = 1 - \\frac{1}{1 + e^{-x}}$$\n",
    "$$1 - \\sigma(x) = \\frac{1 + e^{-x}}{1 + e^{-x}} - \\frac{1}{1 + e^{-x}}$$\n",
    "$$1 - \\sigma(x) = \\frac{(1 + e^{-x}) - 1}{1 + e^{-x}}$$\n",
    "---\n",
    "#### Formula 3:\n",
    "$$1 - \\sigma(x) = \\frac{e^{-x}}{1 + e^{-x}}$$\n",
    "---\n",
    "\n",
    "If we take Formula 2 and put 1 and 3 into it, we get the result we wanted:\n",
    "- $ \\sigma(x) = (1 + e^{-x})^{-1}$\n",
    "- $\\frac{d\\sigma}{dx} = \\left( \\frac{1}{1 + e^{-x}} \\right) \\cdot \\left( \\frac{e^{-x}}{1 + e^{-x}} \\right)$\n",
    "- $1 - \\sigma(x) = \\frac{e^{-x}}{1 + e^{-x}}$\n",
    "$$$$\n",
    "The answer:\n",
    "$$\\frac{d\\sigma}{dx} = \\sigma(x)(1 - \\sigma(x))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b764c",
   "metadata": {},
   "source": [
    "### Qustion 2:\n",
    "$$\\tanh(x) = 2\\sigma(2x) - 1$$\n",
    "---\n",
    "Provide in qustion 1:\n",
    "$$\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$$\n",
    "---\n",
    "$$\\frac{d\\tanh(x)}{dx} = \\frac{d}{dx} (2\\sigma(2x) - 1) = 2 \\cdot \\frac{d}{dx}(\\sigma(2x)) - 0$$\n",
    "$$u = 2x , \\frac{du}{dx} = 2$$\n",
    "$$\\frac{d\\tanh(x)}{dx} = 2 \\cdot \\left[ \\sigma'(u) \\cdot \\frac{du}{dx} \\right]= 2 \\cdot \\left[ \\sigma(u)(1 - \\sigma(u)) \\cdot 2 \\right]= 4 \\sigma(u)(1 - \\sigma(u))$$\n",
    "$$\\frac{d\\tanh(x)}{dx} = 4 \\sigma(2x)(1 - \\sigma(2x))$$\n",
    "$$\\tanh(x) = 2\\sigma(2x) - 1 => \\sigma(2x) = \\frac{1 + \\tanh(x)}{2}$$\n",
    "$$1 - \\sigma(2x) = 1 - \\left( \\frac{1 + \\tanh(x)}{2} \\right) = \\frac{2}{2} - \\frac{1 + \\tanh(x)}{2} = \\frac{2 - 1 - \\tanh(x)}{2} = \\frac{1 - \\tanh(x)}{2}$$\n",
    "\n",
    "---\n",
    "Now using what we found:\n",
    "$$\\frac{d\\tanh(x)}{dx} = 4 \\sigma(2x)(1 - \\sigma(2x)), 1 - \\sigma(2x) = \\frac{1 - \\tanh(x)}{2}, \\sigma(2x) = \\frac{1 + \\tanh(x)}{2}$$\n",
    "We get:\n",
    "$$\\frac{d\\tanh(x)}{dx} = 4 \\cdot \\left[ \\frac{1 + \\tanh(x)}{2} \\right] \\cdot \\left[ \\frac{1 - \\tanh(x)}{2} \\right]= (1 + \\tanh(x))(1 - \\tanh(x))$$\n",
    "---\n",
    "If we open the brakets we get the answer:\n",
    "$$\\frac{d\\tanh(x)}{dx} = 1^2 - \\tanh^2(x) = 1 - \\tanh^2(x)$$\n",
    "$$\\frac{d\\tanh(x)}{dx} = 1 - \\tanh^2(x)$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
