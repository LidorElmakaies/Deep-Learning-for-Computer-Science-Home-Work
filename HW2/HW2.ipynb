{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f19443-dcc5-483e-ad2c-800081f5db16",
   "metadata": {},
   "source": [
    "# Homework #2: Simple Neural Network Implementation using Numpy\n",
    "\n",
    "Today we will build a simple neural network from scratch in Python using only the numpy library. We will follow the instructions from the following link: https://iamtrask.github.io/2015/07/12/basic-python-network/\n",
    "Basic Python Network\n",
    "(Note: The code in the website is written in Python 2, and not Pytho, try writing the code yourself before reverting to the online examplen \n",
    "#1: Import Librarit numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fb5c4-4f4e-41d5-adc9-95f97bb7950a",
   "metadata": {},
   "source": [
    "### Define the Sigmoid Function and its Derivative\n",
    "- Construct a function returning a sigmoid function:\n",
    "$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $\n",
    "- Construct a function returning the derivative of a sigmoid function:\n",
    "$ \\frac{d\\sigma(x)}{dx} = \\sigma(x)(1 - \\sigma(x)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08594d28-1968-4ce6-bac7-4f42bed6ab41",
   "metadata": {},
   "source": [
    "### Initialize Weights\n",
    "Build an array of three weights (3x1 array – think why these dimensions!) and initialize their value randomly. (It is good practice to use weights with normal distribution of $ \\mu = 0 $ and  $ \\sigma = \\frac{1}{3}  $ )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47ab35-6fe8-4fe2-bdda-85d970e810e3",
   "metadata": {},
   "source": [
    "### Training the Neural Network\n",
    "Create a loop, iterating 1000 times (equal to the desired number of learning steps). For each iteration, calculate the difference between the network prediction and the real value of y. Multiply that difference with the sigmoid derivative and use the dot product of this number with the input layer to update your weights for the next iteration.\n",
    "- Input and Output Data Sets\n",
    "``` python\n",
    "X = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1]])on. \t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5cd2d-de64-436e-ae38-3e95c5b04bb7",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "1. Upload the file to your Google Colab or GitHub\n",
    "2. Add your code, run it and test for correcrtness\n",
    "3. Submit a link on moodle to Google Colab or GitHub. Please do not send me the file or a link by mail.\n",
    "4. Make sure to share the link to your notebook with idan.tobis@gmail.com (or make it public)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3891b2",
   "metadata": {},
   "source": [
    "# Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aa33098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b038891",
   "metadata": {},
   "source": [
    "## Define the Sigmoid Function and its Derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Sigmoid activation function.\n",
    "    \n",
    "    Formula: σ(x) = 1 / (1 + e^(-x))\n",
    "    \n",
    "    Args:\n",
    "        x: Input value or array (can be a scalar or numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        The sigmoid of x\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Derivative of the sigmoid function.\n",
    "    \n",
    "    Formula: dσ(x)/dx = σ(x) * (1 - σ(x))\n",
    "    \n",
    "    Args:\n",
    "        x: Input value or array (can be a scalar or numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        The derivative of sigmoid at x\n",
    "    \"\"\"\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff546c",
   "metadata": {},
   "source": [
    "## Initialize Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "114dd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(seed=None):\n",
    "    \"\"\"\n",
    "    Initialize weights for the neural network.\n",
    "    \n",
    "    Creates a 3x1 array of weights initialized with a normal distribution.\n",
    "    The dimensions are 3x1 because:\n",
    "    - Each input sample has 3 features (including bias term)\n",
    "    - We need one weight per input feature\n",
    "    - Output is a single value\n",
    "    \n",
    "    Args:\n",
    "        seed: Optional random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        A 3x1 numpy array of weights with normal distribution (μ=0, σ=1/3)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Normal distribution: μ = 0, σ = 1/3\n",
    "    # Shape: (3, 1) - 3 rows, 1 column\n",
    "    weights = np.random.normal(0, 1/3, size=(3, 1))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5c9da",
   "metadata": {},
   "source": [
    "## Training the Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5da66f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_neural_network(X, y, weights, iterations=1000, print_progress=False):\n",
    "    \"\"\"\n",
    "    Train the neural network using gradient descent.\n",
    "    \n",
    "    For each iteration:\n",
    "    1. Forward pass: Calculate network prediction\n",
    "    2. Calculate error: Difference between prediction and actual value\n",
    "    3. Calculate delta: Multiply error by sigmoid derivative\n",
    "    4. Update weights: Use dot product of input layer with delta\n",
    "    \n",
    "    Args:\n",
    "        X: Input data (n_samples x 3 array)\n",
    "        y: Target output (n_samples x 1 array)\n",
    "        weights: Initial weights (3 x 1 array)\n",
    "        iterations: Number of training iterations (default: 1000)\n",
    "        print_progress: Whether to print progress every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "        Trained weights (3 x 1 array)\n",
    "    \"\"\"\n",
    "    for iteration in range(iterations):\n",
    "        # Forward pass: Calculate network prediction\n",
    "        # X.dot(weights) gives us the weighted sum for each sample\n",
    "        # Then apply sigmoid activation\n",
    "        layer_output = sigmoid(np.dot(X, weights))\n",
    "        \n",
    "        # Calculate error: difference between prediction and actual value\n",
    "        error = y - layer_output\n",
    "        \n",
    "        # Calculate delta: multiply error by sigmoid derivative\n",
    "        # This gives us the gradient direction for weight updates\n",
    "        delta = error * sigmoid_derivative(layer_output)\n",
    "        \n",
    "        # Update weights: use dot product of input layer (X.T) with delta\n",
    "        # X.T.dot(delta) gives us the gradient for each weight\n",
    "        weights += np.dot(X.T, delta)\n",
    "        \n",
    "        # Optional: Print progress\n",
    "        if print_progress and (iteration % 100 == 0 or iteration == iterations - 1):\n",
    "            print(f\"Iteration {iteration}: Error = {np.mean(np.abs(error)):.6f}\")\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c9340",
   "metadata": {},
   "source": [
    "# Testing and using made functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e23d8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid(0) = 0.5\n",
      "Sigmoid derivative(0) = 0.25\n",
      "\n",
      "Sigmoid([-2 -1  0  1  2]) = [0.11920292 0.26894142 0.5        0.73105858 0.88079708]\n",
      "Sigmoid derivative([-2 -1  0  1  2]) = [0.10499359 0.19661193 0.25       0.19661193 0.10499359]\n",
      "\n",
      "============================================================\n",
      "Part 2: Weight Initialization\n",
      "============================================================\n",
      "Weights shape: (3, 1)\n",
      "Weights:\n",
      "[[ 0.16557138]\n",
      " [-0.0460881 ]\n",
      " [ 0.21589618]]\n",
      "\n",
      "Mean: 0.111793 (should be close to 0)\n",
      "Std: 0.113514 (should be close to 0.333333)\n",
      "\n",
      "============================================================\n",
      "Part 3: Training the Neural Network\n",
      "============================================================\n",
      "Input data (X):\n",
      "[[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]]\n",
      "\n",
      "Target output (y):\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "Initial weights:\n",
      "[[ 0.16557138]\n",
      " [-0.0460881 ]\n",
      " [ 0.21589618]]\n",
      "\n",
      "Training for 1000 iterations...\n",
      "Iteration 0: Error = 0.479705\n",
      "Iteration 100: Error = 0.056228\n",
      "Iteration 200: Error = 0.028370\n",
      "Iteration 300: Error = 0.018884\n",
      "Iteration 400: Error = 0.014132\n",
      "Iteration 500: Error = 0.011284\n",
      "Iteration 600: Error = 0.009388\n",
      "Iteration 700: Error = 0.008037\n",
      "Iteration 800: Error = 0.007024\n",
      "Iteration 900: Error = 0.006238\n",
      "Iteration 999: Error = 0.005615\n",
      "\n",
      "Trained weights:\n",
      "[[10.40489995]\n",
      " [-0.41549142]\n",
      " [-4.90933336]]\n",
      "\n",
      "Predictions after training:\n",
      "[[0.00732338]\n",
      " [0.00484561]\n",
      " [0.99591185]\n",
      " [0.993819  ]]\n",
      "\n",
      "Target values:\n",
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "Error (absolute difference):\n",
      "[[0.00732338]\n",
      " [0.00484561]\n",
      " [0.00408815]\n",
      " [0.006181  ]]\n",
      "\n",
      "Mean absolute error: 0.005610\n"
     ]
    }
   ],
   "source": [
    "# Input dataset: 4 samples, each with 3 features (2 inputs + 1 bias term)\n",
    "X = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "\n",
    "# Output dataset: 4 samples, each with 1 output value\n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1]])\n",
    "\n",
    "   # Test with a simple value\n",
    "test_value = 0\n",
    "print(f\"Sigmoid({test_value}) = {sigmoid(test_value)}\")\n",
    "print(f\"Sigmoid derivative({test_value}) = {sigmoid_derivative(test_value)}\")\n",
    "\n",
    "# Test with an array\n",
    "test_array = np.array([-2, -1, 0, 1, 2])\n",
    "print(f\"\\nSigmoid({test_array}) = {sigmoid(test_array)}\")\n",
    "print(f\"Sigmoid derivative({test_array}) = {sigmoid_derivative(test_array)}\")\n",
    "\n",
    "# Test weight initialization\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Part 2: Weight Initialization\")\n",
    "print(\"=\"*60)\n",
    "weights = initialize_weights(seed=42)  # Using seed for reproducibility\n",
    "print(f\"Weights shape: {weights.shape}\")\n",
    "print(f\"Weights:\\n{weights}\")\n",
    "print(f\"\\nMean: {np.mean(weights):.6f} (should be close to 0)\")\n",
    "print(f\"Std: {np.std(weights):.6f} (should be close to {1/3:.6f})\")\n",
    "\n",
    "# Test neural network training\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Part 3: Training the Neural Network\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input data (X):\\n{X}\")\n",
    "print(f\"\\nTarget output (y):\\n{y}\")\n",
    "\n",
    "# Initialize weights for training\n",
    "weights = initialize_weights(seed=42)\n",
    "print(f\"\\nInitial weights:\\n{weights}\")\n",
    "\n",
    "# Train the network\n",
    "print(\"\\nTraining for 1000 iterations...\")\n",
    "trained_weights = train_neural_network(X, y, weights, iterations=1000, print_progress=True)\n",
    "\n",
    "# Test the trained network\n",
    "print(f\"\\nTrained weights:\\n{trained_weights}\")\n",
    "predictions = sigmoid(np.dot(X, trained_weights))\n",
    "print(f\"\\nPredictions after training:\\n{predictions}\")\n",
    "print(f\"\\nTarget values:\\n{y}\")\n",
    "print(f\"\\nError (absolute difference):\\n{np.abs(y - predictions)}\")\n",
    "print(f\"\\nMean absolute error: {np.mean(np.abs(y - predictions)):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
